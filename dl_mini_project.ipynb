{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtW96wvEraiO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# from resnet import *\n",
        "#from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=1, stride=stride, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=1,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=3, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "        self.metric = 0\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [1, 2, 2, 1])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n"
      ],
      "metadata": {
        "id": "JNfFl8uP9K8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBY4HFHIrpXE"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G75IcYw0rztA",
        "outputId": "313be8cf-6200-4f36-b995-ee50a99aec60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA165NUWsM4E"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        #print(batch_idx, len(trainloader), 'Train Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "        #             % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    print(\"\\nTrain Loss:\",train_loss,\"Train acc:\",100.*correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8Na8VuLwlJ3"
      },
      "outputs": [],
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            #print(batch_idx, len(testloader), 'Test Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        acc = 100.*correct/total\n",
        "        print(\"\\nValidation loss\",test_loss,\"Validation Acc:\",acc)\n",
        "    return acc,test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfamY6AkIAYW",
        "outputId": "e53315a2-0632-4c21-9126-94cf05b2212a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n",
            "Using optimizer: Adagrad\n",
            "\n",
            "Epoch: 1\n",
            "\n",
            "Train Loss: 2181.949567437172 Train acc: 48.68\n",
            "\n",
            "Validation loss 109.14375299215317 Validation Acc: 61.02\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Train Loss: 1526.4738805294037 Train acc: 65.316\n",
            "\n",
            "Validation loss 100.42608696222305 Validation Acc: 65.51\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Train Loss: 1299.4874367415905 Train acc: 70.642\n",
            "\n",
            "Validation loss 80.13382029533386 Validation Acc: 72.44\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Train Loss: 1132.2910628914833 Train acc: 74.628\n",
            "\n",
            "Validation loss 74.91791954636574 Validation Acc: 74.14\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "Train Loss: 1001.8050218820572 Train acc: 77.932\n",
            "\n",
            "Validation loss 73.31359818577766 Validation Acc: 75.55\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Train Loss: 923.4051163196564 Train acc: 79.646\n",
            "\n",
            "Validation loss 66.0361756682396 Validation Acc: 77.65\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Train Loss: 853.8455703705549 Train acc: 81.052\n",
            "\n",
            "Validation loss 55.74327617883682 Validation Acc: 81.03\n",
            "\n",
            "Epoch: 8\n",
            "\n",
            "Train Loss: 791.4784535169601 Train acc: 82.67\n",
            "\n",
            "Validation loss 54.76639327406883 Validation Acc: 81.14\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "Train Loss: 747.9270987212658 Train acc: 83.528\n",
            "\n",
            "Validation loss 55.58097153902054 Validation Acc: 80.91\n",
            "\n",
            "Epoch: 10\n",
            "\n",
            "Train Loss: 703.8925381749868 Train acc: 84.588\n",
            "\n",
            "Validation loss 52.54893437027931 Validation Acc: 82.17\n",
            "\n",
            "Epoch: 11\n",
            "\n",
            "Train Loss: 669.6059068441391 Train acc: 85.514\n",
            "\n",
            "Validation loss 49.14880947768688 Validation Acc: 83.26\n",
            "\n",
            "Epoch: 12\n",
            "\n",
            "Train Loss: 633.2459843233228 Train acc: 86.314\n",
            "\n",
            "Validation loss 51.09640169143677 Validation Acc: 82.65\n",
            "\n",
            "Epoch: 13\n",
            "\n",
            "Train Loss: 606.4593356102705 Train acc: 86.728\n",
            "\n",
            "Validation loss 43.57260608673096 Validation Acc: 85.49\n",
            "\n",
            "Epoch: 14\n",
            "\n",
            "Train Loss: 574.5789727941155 Train acc: 87.48\n",
            "\n",
            "Validation loss 50.20564121007919 Validation Acc: 83.48\n",
            "\n",
            "Epoch: 15\n",
            "\n",
            "Train Loss: 551.2779341936111 Train acc: 88.1\n",
            "\n",
            "Validation loss 46.10276210308075 Validation Acc: 84.49\n",
            "\n",
            "Epoch: 16\n",
            "\n",
            "Train Loss: 525.6906518861651 Train acc: 88.414\n",
            "\n",
            "Validation loss 43.663840249180794 Validation Acc: 85.45\n",
            "\n",
            "Epoch: 17\n",
            "\n",
            "Train Loss: 510.6301143690944 Train acc: 88.728\n",
            "\n",
            "Validation loss 41.59118111431599 Validation Acc: 86.18\n",
            "\n",
            "Epoch: 18\n",
            "\n",
            "Train Loss: 486.99893409758806 Train acc: 89.448\n",
            "\n",
            "Validation loss 49.30302447080612 Validation Acc: 84.33\n",
            "\n",
            "Epoch: 19\n",
            "\n",
            "Train Loss: 477.6363490074873 Train acc: 89.472\n",
            "\n",
            "Validation loss 41.803149834275246 Validation Acc: 86.19\n",
            "\n",
            "Epoch: 20\n",
            "\n",
            "Train Loss: 458.0608556084335 Train acc: 89.862\n",
            "\n",
            "Validation loss 48.5297821611166 Validation Acc: 84.21\n",
            "\n",
            "Epoch: 21\n",
            "\n",
            "Train Loss: 438.3467103354633 Train acc: 90.432\n",
            "\n",
            "Validation loss 41.83631284534931 Validation Acc: 86.18\n",
            "\n",
            "Epoch: 22\n",
            "\n",
            "Train Loss: 418.2321473285556 Train acc: 90.854\n",
            "\n",
            "Validation loss 37.60150058567524 Validation Acc: 87.39\n",
            "\n",
            "Epoch: 23\n",
            "\n",
            "Train Loss: 406.6953131072223 Train acc: 91.078\n",
            "\n",
            "Validation loss 41.839313328266144 Validation Acc: 86.7\n",
            "\n",
            "Epoch: 24\n",
            "\n",
            "Train Loss: 386.57774325460196 Train acc: 91.522\n",
            "\n",
            "Validation loss 37.617980286478996 Validation Acc: 87.48\n",
            "\n",
            "Epoch: 25\n",
            "\n",
            "Train Loss: 380.79403122887015 Train acc: 91.614\n",
            "\n",
            "Validation loss 37.953996270895004 Validation Acc: 87.84\n",
            "\n",
            "Epoch: 26\n",
            "\n",
            "Train Loss: 367.56464840099216 Train acc: 91.884\n",
            "\n",
            "Validation loss 37.11782751977444 Validation Acc: 88.07\n",
            "\n",
            "Epoch: 27\n",
            "\n",
            "Train Loss: 356.07519229501486 Train acc: 92.194\n",
            "\n",
            "Validation loss 36.471935257315636 Validation Acc: 88.08\n",
            "\n",
            "Epoch: 28\n",
            "\n",
            "Train Loss: 343.2653578184545 Train acc: 92.466\n",
            "\n",
            "Validation loss 37.68185521662235 Validation Acc: 88.24\n",
            "\n",
            "Epoch: 29\n",
            "\n",
            "Train Loss: 333.59819061122835 Train acc: 92.648\n",
            "\n",
            "Validation loss 36.73872469365597 Validation Acc: 88.14\n",
            "\n",
            "Epoch: 30\n",
            "\n",
            "Train Loss: 319.4935749359429 Train acc: 92.97\n",
            "\n",
            "Validation loss 50.325147554278374 Validation Acc: 84.97\n",
            "\n",
            "Epoch: 31\n",
            "\n",
            "Train Loss: 314.5081849321723 Train acc: 93.122\n",
            "\n",
            "Validation loss 35.5868204459548 Validation Acc: 88.76\n",
            "\n",
            "Epoch: 32\n",
            "\n",
            "Train Loss: 302.9445774368942 Train acc: 93.42\n",
            "\n",
            "Validation loss 34.97842997312546 Validation Acc: 89.17\n",
            "\n",
            "Epoch: 33\n",
            "\n",
            "Train Loss: 291.9657944086939 Train acc: 93.676\n",
            "\n",
            "Validation loss 35.524265602231026 Validation Acc: 88.81\n",
            "\n",
            "Epoch: 34\n",
            "\n",
            "Train Loss: 281.1575339473784 Train acc: 93.838\n",
            "\n",
            "Validation loss 37.491512924432755 Validation Acc: 88.56\n",
            "\n",
            "Epoch: 35\n",
            "\n",
            "Train Loss: 275.97858209721744 Train acc: 93.924\n",
            "\n",
            "Validation loss 40.12486532330513 Validation Acc: 88.06\n",
            "\n",
            "Epoch: 36\n",
            "\n",
            "Train Loss: 260.14323572069407 Train acc: 94.484\n",
            "\n",
            "Validation loss 37.430120170116425 Validation Acc: 88.62\n",
            "\n",
            "Epoch: 37\n",
            "\n",
            "Train Loss: 263.09417828172445 Train acc: 94.206\n",
            "\n",
            "Validation loss 37.546369820833206 Validation Acc: 88.66\n",
            "\n",
            "Epoch: 38\n",
            "\n",
            "Train Loss: 251.71977007947862 Train acc: 94.474\n",
            "\n",
            "Validation loss 37.05625493824482 Validation Acc: 88.95\n",
            "\n",
            "Epoch: 39\n",
            "\n",
            "Train Loss: 242.92826552595943 Train acc: 94.712\n",
            "\n",
            "Validation loss 39.07782246172428 Validation Acc: 88.66\n",
            "\n",
            "Epoch: 40\n",
            "\n",
            "Train Loss: 236.89818440936506 Train acc: 94.91\n",
            "\n",
            "Validation loss 37.2254648655653 Validation Acc: 88.81\n",
            "\n",
            "Epoch: 41\n",
            "\n",
            "Train Loss: 226.72612271085382 Train acc: 95.052\n",
            "\n",
            "Validation loss 35.864449858665466 Validation Acc: 89.15\n",
            "\n",
            "Epoch: 42\n",
            "\n",
            "Train Loss: 222.7715302184224 Train acc: 95.13\n",
            "\n",
            "Validation loss 38.15764990448952 Validation Acc: 88.49\n",
            "\n",
            "Epoch: 43\n",
            "\n",
            "Train Loss: 217.0174412978813 Train acc: 95.262\n",
            "\n",
            "Validation loss 38.73477694392204 Validation Acc: 88.72\n",
            "\n",
            "Epoch: 44\n",
            "\n",
            "Train Loss: 164.94389034248888 Train acc: 96.596\n",
            "\n",
            "Validation loss 33.276200130581856 Validation Acc: 90.04\n",
            "\n",
            "Epoch: 45\n",
            "\n",
            "Train Loss: 146.54616491310298 Train acc: 97.028\n",
            "\n",
            "Validation loss 32.941006898880005 Validation Acc: 90.34\n",
            "\n",
            "Epoch: 46\n",
            "\n",
            "Train Loss: 141.92970912344754 Train acc: 97.172\n",
            "\n",
            "Validation loss 33.33613073825836 Validation Acc: 90.18\n",
            "\n",
            "Epoch: 47\n",
            "\n",
            "Train Loss: 131.34414982842281 Train acc: 97.422\n",
            "\n",
            "Validation loss 32.91344624757767 Validation Acc: 90.46\n",
            "\n",
            "Epoch: 48\n",
            "\n",
            "Train Loss: 128.44064368121326 Train acc: 97.55\n",
            "\n",
            "Validation loss 34.07273609936237 Validation Acc: 90.05\n",
            "\n",
            "Epoch: 49\n",
            "\n",
            "Train Loss: 131.4301646235399 Train acc: 97.42\n",
            "\n",
            "Validation loss 33.64212693274021 Validation Acc: 90.32\n",
            "\n",
            "Epoch: 50\n",
            "\n",
            "Train Loss: 122.08041365025565 Train acc: 97.646\n",
            "\n",
            "Validation loss 33.37685962021351 Validation Acc: 90.24\n",
            "\n",
            "Epoch: 51\n",
            "\n",
            "Train Loss: 123.054868881125 Train acc: 97.656\n",
            "\n",
            "Validation loss 34.29033652693033 Validation Acc: 90.15\n",
            "\n",
            "Epoch: 52\n",
            "\n",
            "Train Loss: 123.92201027134433 Train acc: 97.506\n",
            "\n",
            "Validation loss 33.88018565624952 Validation Acc: 90.1\n",
            "\n",
            "Epoch: 53\n",
            "\n",
            "Train Loss: 118.20436441944912 Train acc: 97.718\n",
            "\n",
            "Validation loss 33.653236128389835 Validation Acc: 90.23\n",
            "\n",
            "Epoch: 54\n",
            "\n",
            "Train Loss: 115.57071072654799 Train acc: 97.76\n",
            "\n",
            "Validation loss 34.06765195727348 Validation Acc: 90.11\n",
            "\n",
            "Epoch: 55\n",
            "\n",
            "Train Loss: 114.06804298935458 Train acc: 97.818\n",
            "\n",
            "Validation loss 34.00725522637367 Validation Acc: 90.09\n",
            "\n",
            "Epoch: 56\n",
            "\n",
            "Train Loss: 111.12504715519026 Train acc: 97.876\n",
            "\n",
            "Validation loss 33.556745685637 Validation Acc: 90.22\n",
            "\n",
            "Epoch: 57\n",
            "\n",
            "Train Loss: 109.38608285342343 Train acc: 97.92\n",
            "\n",
            "Validation loss 34.11807993799448 Validation Acc: 90.33\n",
            "\n",
            "Epoch: 58\n",
            "\n",
            "Train Loss: 106.1686378903687 Train acc: 97.99\n",
            "\n",
            "Validation loss 34.53892121464014 Validation Acc: 90.31\n",
            "\n",
            "Epoch: 59\n",
            "\n",
            "Train Loss: 104.32226079655811 Train acc: 98.052\n",
            "\n",
            "Validation loss 34.15013097971678 Validation Acc: 90.31\n",
            "\n",
            "Epoch: 60\n",
            "\n",
            "Train Loss: 104.76705640275031 Train acc: 98.02\n",
            "\n",
            "Validation loss 33.80792288482189 Validation Acc: 90.49\n",
            "\n",
            "Epoch: 61\n",
            "\n",
            "Train Loss: 105.6329934145324 Train acc: 98.002\n",
            "\n",
            "Validation loss 33.66226602345705 Validation Acc: 90.38\n",
            "\n",
            "Epoch: 62\n",
            "\n",
            "Train Loss: 104.43360852729529 Train acc: 98.03\n",
            "\n",
            "Validation loss 33.959619991481304 Validation Acc: 90.36\n",
            "\n",
            "Epoch: 63\n",
            "\n",
            "Train Loss: 104.29300420568325 Train acc: 97.98\n",
            "\n",
            "Validation loss 33.967839911580086 Validation Acc: 90.3\n",
            "\n",
            "Epoch: 64\n",
            "\n",
            "Train Loss: 102.62607206683606 Train acc: 98.0\n",
            "\n",
            "Validation loss 33.90307615697384 Validation Acc: 90.52\n",
            "\n",
            "Epoch: 65\n",
            "\n",
            "Train Loss: 104.60093857417814 Train acc: 98.044\n",
            "\n",
            "Validation loss 33.91448453813791 Validation Acc: 90.34\n",
            "\n",
            "Epoch: 66\n",
            "\n",
            "Train Loss: 103.10995278134942 Train acc: 98.036\n",
            "\n",
            "Validation loss 33.82328166812658 Validation Acc: 90.4\n",
            "\n",
            "Epoch: 67\n",
            "\n",
            "Train Loss: 101.05329995788634 Train acc: 98.16\n",
            "\n",
            "Validation loss 33.6082928404212 Validation Acc: 90.37\n",
            "\n",
            "Epoch: 68\n",
            "\n",
            "Train Loss: 100.92647796636447 Train acc: 98.182\n",
            "\n",
            "Validation loss 34.15296448022127 Validation Acc: 90.44\n",
            "\n",
            "Epoch: 69\n",
            "\n",
            "Train Loss: 104.36465325648896 Train acc: 97.954\n",
            "\n",
            "Validation loss 33.693618811666965 Validation Acc: 90.45\n",
            "\n",
            "Epoch: 70\n",
            "\n",
            "Train Loss: 102.76684363512322 Train acc: 98.044\n",
            "\n",
            "Validation loss 33.97352730482817 Validation Acc: 90.28\n",
            "\n",
            "Epoch: 71\n",
            "\n",
            "Train Loss: 102.65759301092476 Train acc: 98.114\n",
            "\n",
            "Validation loss 33.97894260287285 Validation Acc: 90.37\n",
            "\n",
            "Epoch: 72\n",
            "\n",
            "Train Loss: 100.63671236205846 Train acc: 98.138\n",
            "\n",
            "Validation loss 33.67352565377951 Validation Acc: 90.38\n",
            "\n",
            "Epoch: 73\n",
            "\n",
            "Train Loss: 102.48429502779618 Train acc: 98.112\n",
            "\n",
            "Validation loss 34.50293804705143 Validation Acc: 90.29\n",
            "\n",
            "Epoch: 74\n",
            "\n",
            "Train Loss: 101.9312530043535 Train acc: 98.06\n",
            "\n",
            "Validation loss 34.18118903040886 Validation Acc: 90.3\n",
            "\n",
            "Epoch: 75\n",
            "\n",
            "Train Loss: 101.12991157500073 Train acc: 98.038\n",
            "\n",
            "Validation loss 33.67150954902172 Validation Acc: 90.45\n",
            "\n",
            "Epoch: 76\n",
            "\n",
            "Train Loss: 101.89702956844121 Train acc: 98.106\n",
            "\n",
            "Validation loss 34.251350708305836 Validation Acc: 90.33\n",
            "\n",
            "Epoch: 77\n",
            "\n",
            "Train Loss: 100.32982903975062 Train acc: 98.056\n",
            "\n",
            "Validation loss 34.1488334313035 Validation Acc: 90.39\n",
            "\n",
            "Epoch: 78\n",
            "\n",
            "Train Loss: 100.31763060577214 Train acc: 98.098\n",
            "\n",
            "Validation loss 33.56616308540106 Validation Acc: 90.49\n",
            "\n",
            "Epoch: 79\n",
            "\n",
            "Train Loss: 101.47567051742226 Train acc: 98.146\n",
            "\n",
            "Validation loss 34.077679209411144 Validation Acc: 90.53\n",
            "\n",
            "Epoch: 80\n",
            "\n",
            "Train Loss: 100.41316228848882 Train acc: 98.16\n",
            "\n",
            "Validation loss 33.89180247485638 Validation Acc: 90.26\n",
            "\n",
            "Epoch: 81\n",
            "\n",
            "Train Loss: 100.72970964992419 Train acc: 98.122\n",
            "\n",
            "Validation loss 33.79663896560669 Validation Acc: 90.42\n",
            "\n",
            "Epoch: 82\n",
            "\n",
            "Train Loss: 101.25744037283584 Train acc: 98.096\n",
            "\n",
            "Validation loss 34.161026276648045 Validation Acc: 90.6\n",
            "\n",
            "Epoch: 83\n",
            "\n",
            "Train Loss: 100.71589894592762 Train acc: 98.138\n",
            "\n",
            "Validation loss 34.650026731193066 Validation Acc: 90.16\n",
            "\n",
            "Epoch: 84\n",
            "\n",
            "Train Loss: 105.47361319884658 Train acc: 98.034\n",
            "\n",
            "Validation loss 34.18306416273117 Validation Acc: 90.51\n",
            "\n",
            "Epoch: 85\n",
            "\n",
            "Train Loss: 104.06086167320609 Train acc: 98.03\n",
            "\n",
            "Validation loss 34.40219160914421 Validation Acc: 90.3\n",
            "\n",
            "Epoch: 86\n",
            "\n",
            "Train Loss: 100.18895801808685 Train acc: 98.106\n",
            "\n",
            "Validation loss 33.900236159563065 Validation Acc: 90.54\n",
            "\n",
            "Epoch: 87\n",
            "\n",
            "Train Loss: 100.18632166762836 Train acc: 98.102\n",
            "\n",
            "Validation loss 34.326700903475285 Validation Acc: 90.37\n",
            "\n",
            "Epoch: 88\n",
            "\n",
            "Train Loss: 102.54835584550165 Train acc: 98.112\n",
            "\n",
            "Validation loss 34.060618698596954 Validation Acc: 90.27\n",
            "\n",
            "Epoch: 89\n",
            "\n",
            "Train Loss: 100.52213665784802 Train acc: 98.18\n",
            "\n",
            "Validation loss 33.75360772758722 Validation Acc: 90.32\n",
            "\n",
            "Epoch: 90\n",
            "\n",
            "Train Loss: 100.9009814071469 Train acc: 98.118\n",
            "\n",
            "Validation loss 34.043393544852734 Validation Acc: 90.47\n",
            "\n",
            "Epoch: 91\n",
            "\n",
            "Train Loss: 99.29986808868125 Train acc: 98.118\n",
            "\n",
            "Validation loss 34.34815115481615 Validation Acc: 90.23\n",
            "\n",
            "Epoch: 92\n",
            "\n",
            "Train Loss: 100.9397819195874 Train acc: 98.104\n",
            "\n",
            "Validation loss 33.6152194365859 Validation Acc: 90.26\n",
            "\n",
            "Epoch: 93\n",
            "\n",
            "Train Loss: 103.18073394009843 Train acc: 98.05\n",
            "\n",
            "Validation loss 34.17738018929958 Validation Acc: 90.33\n",
            "\n",
            "Epoch: 94\n",
            "\n",
            "Train Loss: 100.99532072572038 Train acc: 98.142\n",
            "\n",
            "Validation loss 33.8699154406786 Validation Acc: 90.46\n",
            "\n",
            "Epoch: 95\n"
          ]
        }
      ],
      "source": [
        "all_acc = []\n",
        "\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "  net = torch.nn.DataParallel(net)\n",
        "  cudnn.benchmark = True\n",
        "optimizerDict = {\n",
        "                    \"SGD\" : optim.SGD(net.parameters(), lr=0.1,\n",
        "                        momentum=0.9, weight_decay=5e-4),\n",
        "                    \"SGDNesterov\" : optim.SGD(net.parameters(), lr=0.1,\n",
        "                        momentum=0.9, nesterov = True, weight_decay=5e-4),\n",
        "                    \"Adam\" : optim.Adam(net.parameters(),lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-4, \n",
        "                        amsgrad=False, foreach=None, maximize=False, capturable=False),\n",
        "                    \"Adadelta\" : optim.Adadelta(net.parameters(), lr=0.1, rho=0.9, eps=1e-08, \n",
        "                        weight_decay=5e-4, foreach=None, maximize=False),\n",
        "                    \"Adagrad\" : optim.Adagrad(net.parameters(), lr=0.01, lr_decay=0, \n",
        "                        weight_decay=5e-4, initial_accumulator_value=0, eps=1e-08, foreach=None, maximize=False)\n",
        "                } \n",
        "epoch = 0\n",
        "acc_array = []\n",
        "print('==> Building model..')\n",
        "optimizer = optimizerDict[\"Adagrad\"]\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "print(\"Using optimizer:\",\"Adagrad\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "while epoch<100:\n",
        "    epoch+=1\n",
        "    train(epoch)\n",
        "    va,loss = test(epoch)\n",
        "    acc_array.append(va)\n",
        "    scheduler.step(loss)\n",
        "print(best_acc)\n",
        "all_acc.append(acc_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNigcVFkReb1"
      },
      "outputs": [],
      "source": [
        "print(all_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCxuqu-AR0QS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}